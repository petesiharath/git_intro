{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Programming and Data Analysis for Scientists![image.png]\n",
    "## Workshop 6: Consolidation\n",
    "## Monday 30th October 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reminders\n",
    "- We are currently in week 6. \n",
    "- Complete test 2 which is due at midday (12pm) on Wednesday 1st November. \n",
    "- This is worth 5% of your unit mark. \n",
    "\n",
    "- There will be a seminar during week 9. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Recap of previous workshops \n",
    "\n",
    "## Workshop 4\n",
    "- Data exploration and visualisation\n",
    "- Correlations\n",
    "- Data trends and regression models\n",
    "\n",
    "## Workshop 5\n",
    "- Supervised learning and unsupervised learning\n",
    "- Model validation \n",
    "- Using sample weights and uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflective practice\n",
    "\n",
    "## What debugging strategies did you use in workshops 4 and 5? \n",
    "\n",
    "\n",
    "## What progressions in learning material are you noticing moving from year 1 to year 2?\n",
    "\n",
    "\n",
    "Padlet details \n",
    "- https://uob.padlet.org/mairegorman/post-workshop-5-padlet-panrop3xmqaxoelr\n",
    "- Password: scif20002-workshop-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Today's session\n",
    "\n",
    "**Aim:** Consolidate material from Data Science 1 and 2 through exercises\n",
    "\n",
    "- How to transform variables to perform linear regression and make calculations using regression coefficients\n",
    "    - Workshop6_01_linear_regression_coefficients.ipynb\n",
    "    \n",
    "\n",
    "- How to load data from a database and work with date time indexes\n",
    "    - Workshop6_02_database_time_index.ipynb\n",
    "    \n",
    "    \n",
    "- How we can use categorical variables in regression models\n",
    "    - Workshop6_03_categorical_variables.ipynb\n",
    "    \n",
    "    \n",
    "- Bonus **(optional!)**: Example of using the nearest neighbours algorithm to predict categorical information\n",
    "    - Workshop6_04_nearest_neighbours.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transforming variables for linear regression and using coefficients\n",
    "\n",
    "- In **Workshops 4** and **5** you learned to use scikit-learn to build linear regression models and extract model parameters.\n",
    "- In **Workshop 5** you learned how to use sample weights when training a regression model.\n",
    "\n",
    "In our first notebook we're going to work through an example using a dataset that contains two variables with a non-linear relationship. \n",
    "- Using theoretical knowledge of the form of the relationship between these input variables, we're going to transform one of the variables so that a linear relationship can be exploited.\n",
    "- Using information on the measurement uncertainty of our data, we're going to try to improve the performance of a regression model.\n",
    "- Using the coefficient of our regression, we're going to calculate a relevant physical quantity.\n",
    "\n",
    "[Workshop5_01_linear_regression_coefficients](Workshop5_01_linear_regression_coefficients.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression: transforming variables \n",
    "![Alt](img/Transformation.PNG \"Transforming variables for the purposes of linear regression\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Databases, time indexing and resampling\n",
    "\n",
    "- In **Workshop 2** you were introduced to working with sqlite database files. \n",
    "- In **Workshop 3** you used `resample` to average timeseries data over periods of time.\n",
    "\n",
    "In the second notebook we're going to revisit working with time series data and extracting that data from a database source. \n",
    "\n",
    "[Workshop6_02_database_time_index](Workshop6_02_database_time_index.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mentimeter activity\n",
    "\n",
    "### In the global temperatures dataset, what biases could there be? Think back to our discussion on biases in research.\n",
    "\n",
    "menti.com, code: 3619 0611\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Categorical variables in regression models\n",
    "\n",
    "- In **Workshop 4** we explored the different data types within our data. We noted that while some of our data was numeric, it also contained _categorical_ information.\n",
    "\n",
    "In the third notebook we're going to look at how we can make use of categorical data in regression models. For the models we've been working with we've only made use of numeric information from the data we have available to us, but categorical data can provide additional information that may prove useful in improving our model performance. \n",
    "\n",
    "[Workshop6_03_categorical_variables](Workshop6_03_categorical_variables.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus Exercise: Nearest Neighbours\n",
    "\n",
    "If you are happy with the previous three notebooks, then you are welcome to work through the final bonus notebook. \n",
    "\n",
    "In this notebook we work through an example of another supervised learning algorithm: $k$-nearest neighbours. This is interesting for the following reasons:\n",
    "- This is an example of how we can use information to predict which _category_ our data falls into.\n",
    "- You will find that the procedure and steps that we need to follow in order to set up our model and make our predictions is the same as the procedure that you're become familiar with while building your regression models.\n",
    "\n",
    "\n",
    "[Workshop6_04_nearest_neighbours](Workshop6_04_nearest_neighbours.ipynb)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
